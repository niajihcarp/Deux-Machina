1] So, it is true that having a finer discretizaton should have a better result cause it represents the environment in much more detail. But while training the model, the model with a lot more discretizatons would need a lot more episodes of training to accurately define the Q-table, as the observation space has a lot more finer differences, so it cannot broadly distinguish (like the one with less discretizatons) between the observations and is essentially confused/not completely informed yet about the observation space. Therefore, having a bad score in a small training episode size.

2] As we increase the size of episodes for which the models are trained for, we can clearly see the advantage of having a finer discretizaton as it outperforms the other model by a big margin. This happened cause when we increased the episode size, the finer model got the sufficient episodes to make fine (ik im using this word a lot, but I can't find any better alternative rn) judgements/entries in the Q-table to distinguish between good and bad moves with immense precision and therefore, outperforms the model with blunt discretizations.

3] So the problem with this method is that for the edge cases, i.e., the end points of our intervals (like 0.5 and 0.99 for the interval of range [0.5,1)), it treats both of the cases as the same, as they belong to the same interval, and this can be a big problem, as both of the cases can have very different meanings/weightage for identifying the current state of the system and taking appropriate actions.

4] Naturally, yes. As we discussed earlier, the finer the discretization the more it represents the natural environment, and therefore, it would give a better model with finer details and understanding of the system, given that it is given an appropriately large training episode size.
