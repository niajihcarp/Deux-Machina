{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e20b8d68",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62441e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbe5a2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Q table: [[ 0.93761173  1.03190674 -0.34911835 -0.27341211]\n",
      " [-1.58269615  1.85745956  0.01164501 -0.58940133]\n",
      " [-0.82743845 -0.53487351  0.00818297  0.2656737 ]\n",
      " [ 0.03530733 -1.4861868   0.11047334 -0.03284743]\n",
      " [ 0.09081534 -0.54011704  1.20113396 -1.7136453 ]\n",
      " [-0.75309776  1.93891147  0.56151487  0.95065349]\n",
      " [-0.434802    0.13074478  0.48886974 -0.59063403]\n",
      " [-0.03655272  1.34224428  0.94643352 -0.86591202]\n",
      " [-1.06613085  2.04626752 -0.48494637 -1.40385192]\n",
      " [ 0.88953151 -0.13372451 -0.82145143 -0.36214895]\n",
      " [ 1.20594471 -2.11878403 -0.94016621 -1.66436867]\n",
      " [ 0.64701079 -0.39451895  0.48522483 -0.53380254]\n",
      " [-1.21233086  0.81499479  0.59793537  0.34495765]\n",
      " [ 0.22123134 -1.38470268  1.01223443  1.41427946]\n",
      " [-0.32363901  0.30533926 -0.32245769 -1.2673961 ]\n",
      " [ 0.          0.          0.          0.        ]]\n",
      "Final Q table: [[ 7.35091891  7.73780937  7.73780937  7.35091891]\n",
      " [ 7.35091891 -3.1580341   8.1450625   7.73780937]\n",
      " [ 7.73780937  8.57375     7.73780937  8.1450625 ]\n",
      " [ 8.1450625  -3.72486793  7.73780758  7.73774784]\n",
      " [ 7.73780937  8.1450625  -3.1580341   7.35091891]\n",
      " [-0.75309776  1.93891147  0.56151487  0.95065349]\n",
      " [-3.1580341   9.025      -3.72486793  8.1450625 ]\n",
      " [-0.03655272  1.34224428  0.94643352 -0.86591202]\n",
      " [ 8.1450625  -4.22575495  8.57375     7.73780937]\n",
      " [ 8.1450625   9.025       9.025      -3.1580341 ]\n",
      " [ 8.57375     9.5        -4.38533975  8.57375   ]\n",
      " [ 0.64701079 -0.39451895  0.48522483 -0.53380254]\n",
      " [-1.21233086  0.81499479  0.59793537  0.34495765]\n",
      " [-4.22575495  9.025       9.5         8.57375   ]\n",
      " [ 9.025       9.5        10.          9.025     ]\n",
      " [ 0.          0.          0.          0.        ]]\n"
     ]
    }
   ],
   "source": [
    "a=0.8 #learning rate\n",
    "g=0.95 #discount factor\n",
    "\n",
    "rng=np.random.default_rng() #random number generator\n",
    "\n",
    "env=gym.make(\n",
    "    'FrozenLake-v1',\n",
    "    desc=None,\n",
    "    map_name=\"4x4\",\n",
    "    is_slippery=False,\n",
    "    reward_schedule=(10,-5,0),\n",
    ")\n",
    "\n",
    "def select_action(Q,S,e):\n",
    "    x=rng.random()\n",
    "    if x<e:\n",
    "        return rng.integers(low=0,high=4)\n",
    "    else:\n",
    "        return Q[S].argmax()\n",
    "\n",
    "Q=np.random.randn(64).reshape((16,4)) #make a arbitrary Q table and store it as a 16x4 array\n",
    "Q[15]=[0,0,0,0]\n",
    "print(\"Initial Q table:\",Q)\n",
    "\n",
    "state,info=env.reset()\n",
    "run=True\n",
    "n=0\n",
    "\n",
    "while n<10000:\n",
    "    while run:\n",
    "        e=max(0.01,0.999**n) # eps_start=1, eps_end=0.01, eps_decay=0.999, epsilon = max(eps_end, eps_start*(eps_decay)**(episode_number))\n",
    "        action = select_action(Q,state,e)\n",
    "        prev_state=state\n",
    "        state, reward, terminated, truncated, info = env.step(action)\n",
    "        q=Q[state].max()\n",
    "        Q[prev_state][action]+=a*(reward+g*q-Q[prev_state][action]) # Q learning implementation\n",
    "\n",
    "        if truncated or terminated:\n",
    "            state, info=env.reset()\n",
    "            run=False\n",
    "    n+=1\n",
    "    run=True\n",
    "\n",
    "print(\"Final Q table:\",(Q))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e71ace",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c022f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "env1=gym.make(\n",
    "    'FrozenLake-v1',\n",
    "    desc=None,\n",
    "    map_name=\"4x4\",\n",
    "    is_slippery=False,\n",
    "    reward_schedule=(10, -5, 0),\n",
    "    render_mode=\"human\"\n",
    ")\n",
    "\n",
    "run=True\n",
    "state, info=env1.reset()\n",
    "while run:\n",
    "    action =  Q[state].argmax()\n",
    "    state, reward, terminated, truncated, info = env1.step(action)\n",
    "\n",
    "    if truncated or terminated:\n",
    "        state, info=env1.reset()\n",
    "        run=False\n",
    "env1.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
